# **Lip_Sync**: *Accurately Lip-syncing Videos In The Wild*
Note: The model has been cloned and the rights remain intact. To run the project you must have older version of Python.
Steps to run the project
1) Download the code from this respo
2) Make sure to specify the audio and video path in checkpoint file
3) The result will be in results folder
4) To run the code make sure to pip install requirements.txt
5) The command to run the code is python inference.py --checkpoint_path <ckpt> --face <video.mp4> --audio <an-audio-source>
6) The video used is present in ![(https://drive.google.com/file/d/1RuYg-Pvf-rmjZDvTBmUhVNPaHQN6SH3_/view?usp=sharing)https://drive.google.com/file/d/1RuYg-Pvf-rmjZDvTBmUhVNPaHQN6SH3_/view?usp=sharing)] and audio is present in the folder
7) Result is in ![(https://drive.google.com/file/d/1pVVfYqrOI2OJXTTOHWLdf61W6nbO4YEg/view?usp=sharing)https://drive.google.com/file/d/1pVVfYqrOI2OJXTTOHWLdf61W6nbO4YEg/view?usp=sharing)]
8) After running the project the final result will be saved in results folder since Github is not allowing me to upload such huge files, I have attached Drive link.
